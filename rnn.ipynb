{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Layers\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        encoded = self.encoder(x)\n",
    "        y, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        y = self.decoder(y.view(batch_size, -1))\n",
    "        return y, hidden\n",
    "\n",
    "    def forward2(self, x, hidden):\n",
    "        encoded = self.encoder(x.view(1, -1))\n",
    "        y, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
    "        y = self.decoder(y.view(1, -1))\n",
    "        return y, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 825\n",
    "hidden_size = 32\n",
    "chunk_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = CharRNN(vocab_size, hidden_size, vocab_size, n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = torch.Tensor(np.load('./data/Fallujah - Cerebral Hybridization - 0.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_len = len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(filename, chunk_len, batch_size):\n",
    "    \n",
    "    file = torch.Tensor(np.load(filename))\n",
    "    file_len = len(file)\n",
    "    \n",
    "    input = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        start = random.randint(0, file_len - chunk_len)\n",
    "        end = start_index + chunk_len + 1\n",
    "        \n",
    "        chunk = file[start:end]\n",
    "        \n",
    "        input[i] = chunk[:-1]\n",
    "        target[i] = chunk[1:]\n",
    "        \n",
    "    input = Variable(input)\n",
    "    target = Variable(target)\n",
    "    \n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[295, 283, 302, 283, 300, 283, 300, 302, 283, 300],\n",
       "         [301, 300, 296, 295, 296, 295, 289, 295, 289, 296],\n",
       "         [181, 181, 181, 181, 181, 178, 178, 178, 178, 178],\n",
       "         [295, 288, 295, 303, 295, 288, 295, 302, 295, 288],\n",
       "         [303, 284, 302, 284, 302, 303, 284, 302, 284, 302],\n",
       "         [303, 295, 288, 295, 302, 295, 288, 295, 296, 295],\n",
       "         [308, 307, 301, 300, 301, 300, 296, 295, 294, 294],\n",
       "         [449, 454, 461, 460, 494, 461, 454, 449, 606, 295],\n",
       "         [329, 278, 277, 275, 112, 118, 118, 118, 118, 118],\n",
       "         [295, 303, 295, 288, 295, 293, 300, 293, 300, 307],\n",
       "         [283, 290, 283, 283, 283, 283, 285, 286, 290, 291],\n",
       "         [283, 329, 118, 118, 118, 118, 118, 118, 118, 118],\n",
       "         [302, 284, 303, 284, 284, 284, 284, 284, 284, 284],\n",
       "         [293, 307, 300, 293, 300, 293, 307, 300, 293, 300],\n",
       "         [281, 281, 281, 281, 281, 281, 281, 673, 460, 453],\n",
       "         [179, 179, 179, 179, 174, 174, 174, 174, 174, 174],\n",
       "         [118, 118, 118, 118, 118, 118, 118, 118, 118, 118],\n",
       "         [296, 296, 296, 296, 296, 296, 296, 296, 296, 296],\n",
       "         [296, 295, 288, 295, 303, 295, 288, 295, 293, 300],\n",
       "         [294, 294, 294, 294, 294, 294, 293, 293, 293, 293],\n",
       "         [178, 178, 178, 178, 178, 179, 179, 179, 179, 179],\n",
       "         [449, 454, 461, 460, 494, 461, 454, 449, 606, 295],\n",
       "         [329, 278, 277, 275, 112, 118, 118, 118, 118, 118],\n",
       "         [302, 295, 288, 295, 303, 295, 288, 295, 302, 295],\n",
       "         [302, 283, 300, 283, 302, 303, 284, 302, 284, 302],\n",
       "         [179, 179, 174, 174, 174, 174, 174, 174, 174, 174],\n",
       "         [294, 294, 294, 294, 294, 294, 294, 294, 294, 294],\n",
       "         [302, 283, 300, 283, 302, 303, 284, 302, 284, 302],\n",
       "         [295, 295, 295, 295, 295, 295, 295, 295, 295, 295],\n",
       "         [296, 463, 461, 454, 461, 449, 454, 461, 460, 278],\n",
       "         [296, 296, 294, 294, 294, 294, 294, 294, 294, 294],\n",
       "         [295, 295, 295, 295, 295, 295, 295, 296, 296, 296]]),\n",
       " tensor([[283, 302, 283, 300, 283, 300, 302, 283, 300, 283],\n",
       "         [300, 296, 295, 296, 295, 289, 295, 289, 296, 289],\n",
       "         [181, 181, 181, 181, 178, 178, 178, 178, 178, 178],\n",
       "         [288, 295, 303, 295, 288, 295, 302, 295, 288, 295],\n",
       "         [284, 302, 284, 302, 303, 284, 302, 284, 302, 303],\n",
       "         [295, 288, 295, 302, 295, 288, 295, 296, 295, 288],\n",
       "         [307, 301, 300, 301, 300, 296, 295, 294, 294, 294],\n",
       "         [454, 461, 460, 494, 461, 454, 449, 606, 295, 296],\n",
       "         [278, 277, 275, 112, 118, 118, 118, 118, 118, 118],\n",
       "         [303, 295, 288, 295, 293, 300, 293, 300, 307, 293],\n",
       "         [290, 283, 283, 283, 283, 285, 286, 290, 291, 297],\n",
       "         [329, 118, 118, 118, 118, 118, 118, 118, 118, 283],\n",
       "         [284, 303, 284, 284, 284, 284, 284, 284, 284, 284],\n",
       "         [307, 300, 293, 300, 293, 307, 300, 293, 300, 293],\n",
       "         [281, 281, 281, 281, 281, 281, 673, 460, 453, 446],\n",
       "         [179, 179, 179, 174, 174, 174, 174, 174, 174, 174],\n",
       "         [118, 118, 118, 118, 118, 118, 118, 118, 118, 118],\n",
       "         [296, 296, 296, 296, 296, 296, 296, 296, 296, 296],\n",
       "         [295, 288, 295, 303, 295, 288, 295, 293, 300, 293],\n",
       "         [294, 294, 294, 294, 294, 293, 293, 293, 293, 293],\n",
       "         [178, 178, 178, 178, 179, 179, 179, 179, 179, 179],\n",
       "         [454, 461, 460, 494, 461, 454, 449, 606, 295, 296],\n",
       "         [278, 277, 275, 112, 118, 118, 118, 118, 118, 118],\n",
       "         [295, 288, 295, 303, 295, 288, 295, 302, 295, 288],\n",
       "         [283, 300, 283, 302, 303, 284, 302, 284, 302, 303],\n",
       "         [179, 174, 174, 174, 174, 174, 174, 174, 174, 174],\n",
       "         [294, 294, 294, 294, 294, 294, 294, 294, 294, 293],\n",
       "         [283, 300, 283, 302, 303, 284, 302, 284, 302, 303],\n",
       "         [295, 295, 295, 295, 295, 295, 295, 295, 295, 295],\n",
       "         [463, 461, 454, 461, 449, 454, 461, 460, 278, 277],\n",
       "         [296, 294, 294, 294, 294, 294, 294, 294, 294, 294],\n",
       "         [295, 295, 295, 295, 295, 295, 296, 296, 296, 296]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_training_set(10, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
